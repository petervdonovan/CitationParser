{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ParserEvaluation2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSQQxLc+0znzIiNz67/ZXe"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"V0lYhtjCpq9X"},"source":["# Parser Evaluation\r\n","\r\n","There is an [earlier version](https://colab.research.google.com/github/petervdonovan/CitationParser/blob/master/ParserEvaluation.ipynb) of this notebook, and much of the work contained in this notebook is different from but parallel to this earlier version. There are a few reasons why it was necessary to rethink this prior work:\r\n","1. Tags will not be a component of the testing or training dataset.\r\n","    * This does not mean that tags will not continue to be important. However, I have decided that the our objective -- use of citations to create edges in a social network -- does not inherently involve tagging.\r\n","1. In lieu of tags, metadata is being included in a format that is as independent from its origin as possible.\r\n","    * Names in particular do require this. In bibliographic entries, the formatting of names varies widely by style guide. If names are to be considered as semantic information instead of as raw text, they should be presented in a data structure that makes the different parts of a name explicit.\r\n","1. Metrics used to evaluate models will be carefully chosen to make them as interpretable as possible for individuals who do not know any low-level details of how our models operate.\r\n","    * Changes in this direction reduce the amount of text that is required alongside any reported metrics.\r\n","\r\n","There may be several parts of this notebook where you may cry out, \"I have seen all of this before, in another notebook! This is not DRY!\" I insist on justifying myself by noting that in writing this notebook I have a slightly different purpose in mind, and that I do not wish to be constrained by any links or dependencies on an implementation that I may not wish to keep."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqBT1GGgy6X1","executionInfo":{"status":"ok","timestamp":1614578647271,"user_tz":480,"elapsed":3537,"user":{"displayName":"Peter Donovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmevrWa6lY-MoKL6lRCYdlS09IgSTYxUPNKCYZ=s64","userId":"01568505250649921698"}},"outputId":"3bff0e34-a48f-4825-ee89-730b7cdc969f"},"source":["!pip install pickle5\r\n","import pandas as pd\r\n","import numpy as np\r\n","import pickle5 as pickle\r\n","import random\r\n","import time\r\n","import matplotlib.pyplot as plt\r\n","from gensim.utils import simple_preprocess\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","%cd /content/drive/MyDrive/AWCA/Colab_notebooks/CitationTagging/Sp21/CitationParser/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.11)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1W2EROe2FItlaK99U-WY_qaBOc2UD_LI0/AWCA/Colab_notebooks/CitationTagging/Sp21/CitationParser\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R3I_B8gFwTD8"},"source":["## Datasets\r\n","\r\n","### Note on dataset selection\r\n","\r\n","For the moment, I will be loading the OpenCitations dataset for initial tests. There are a couple of serious limitations to this dataset which we should be aware of:\r\n","* It has a replicability issue: Because the OpenCitations dataset is too large to support a SPARQL query that asks for the DOI of _every_ cited work for which we have a raw-text citation, I had to use a LIMIT clause. There are no promises about whether the sample I got was representative of the corpus, so this is a little unfortunate.\r\n","* It is probably dissimilar to our dataset in important ways. Specifically, many of the bibliographic entities documented in the particular portion of the dataset that I have downloaded are journal articles on biology and medicine -- a fact that may be reflected in the style guides that are used.\r\n","\r\n","For these reasons, OpenCitations is an additional tool, not a replacement for our other datasets. I am using it for the moment so that I can focus on developing a parser using a clean dataset, without having to worry about whether my results are valid or whether the dataset generation process has bugs.\r\n","\r\n","Another challenge is that the Zotero dataset does not have raw text citations that are reliably matched with the corresponding metadata. A _mostly_ successful attempt to tackle this issue is included in [this notebook](https://colab.research.google.com/drive/1OEFWVWgEzCiPA35Ma20svEY5OhPCuPwI), but it is a beast, and the output has imperfections of a severity that is difficult to quantify definitively.\r\n","\r\n","In any case, the OpenCitations dataset will be used for development. Long-term goals might be:\r\n","* To include a more representative (or complete) sample of the OpenCitations corpus, for replicability, and\r\n","* To include the Zotero dataset.\r\n","\r\n","### Fields in the Dataset\r\n","\r\n","The dataset has the following fields for the models to use for prediction:\r\n","* **raw**: The raw text citation, represented as a string.\r\n","\r\n","The dataset has the following fields for the models to predict:\r\n","* **author**: The name(s) of the authors of the work, represented as `Name` objects.\r\n","* **year**: The publication year of the work, represented as an integer.\r\n","* **title**: The title of the work, represented as a string.\r\n","\r\n","These three fields are the ones that are likely candidates to be used to construct edges; the others are much more questionable. Each of them is commonly found -- for example, 98.8% of records in the Zotero database have a publication year, 99.6% have an author, and 99.7% have a title.\r\n","\r\n","Every row used in this dataset will have all three fields, i.e., the datasets will look like someone called `dropna` on them to eliminate null values in those columns. I acknowledge that this means that what is left may not be representative of the raw-text citations that may be out there in the wild; however, as mentioned in the above paragraph, those three fields are fairly commonplace.\r\n","\r\n","It is worth noting, however, that other fields are available in case we decide to incorporate them into our analysis later. They are less common and less reliable, so I would only include them as a very late micro-optimization to our model, if at all.\r\n","* pages: The pages in which the work appeared in the container (book, anthology, journal issue, etc.) in which it was published, represented as a string containing digits, a hyphen, and then more digits (or just digits, if the work appears on only one page)\r\n","* volume: The volume in which the work appears, represented as a string.\r\n","* source_title: The name of the journal or other entity responsible for the publication of the work.\r\n","* issue: The issue in which the work appeared.\r\n","\r\n","Matching surnames, matching titles, and matching years should be sufficient grounds for declaring a match. `simple_preprocess` from Gensim.utils with deacc=True should be enough to get reliable matches, if the fields can just be extracted correctly.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"-xBDR6gfm1go","colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"status":"ok","timestamp":1614579656812,"user_tz":480,"elapsed":540,"user":{"displayName":"Peter Donovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmevrWa6lY-MoKL6lRCYdlS09IgSTYxUPNKCYZ=s64","userId":"01568505250649921698"}},"outputId":"5e246476-2ef1-4cf2-f90f-3c829fd0f92e"},"source":["with open('datasets/occ_45K.pickle', 'rb') as dbfile:\r\n","  occ_45K = pickle.load(dbfile)\r\n","occ = pd.DataFrame()\r\n","occ['raw']    = occ_45K.raw\r\n","occ['author'] = occ_45K.author\r\n","occ['year']   = occ_45K.year\r\n","occ['title']  = occ_45K.title\r\n","print('I wished to get metadata for {} DOIs downloaded from the OpenCitations\\n'\r\n","      'SPARQL endpoint, '.format(\r\n","    len(occ.index)\r\n","), end='')\r\n","occ = occ.dropna()\r\n","print('but only {} complete rows of metadata were received.'.format(\r\n","    len(occ.index)\r\n","))\r\n","occ.sample(2)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["I wished to get metadata for 45756 DOIs downloaded from the OpenCitations\n","SPARQL endpoint, but only 45280 complete rows of metadata were received.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw</th>\n","      <th>author</th>\n","      <th>year</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22890</th>\n","      <td>Li, Y, Zou, S, Wang, D, Feng, G, Bao, C, Hu, J...</td>\n","      <td>Li, Yunfeng; Zou, Shujuan; Wang, Dazhang; Feng...</td>\n","      <td>2010</td>\n","      <td>The Effect Of Hydrofluoric Acid Treatment On T...</td>\n","    </tr>\n","    <tr>\n","      <th>12621</th>\n","      <td>N. Fucci, C. Gambelunghe, K. Aroni, R. Rossi. ...</td>\n","      <td>Fucci, Nadia; Gambelunghe, Cristiana; Aroni, K...</td>\n","      <td>2014</td>\n","      <td>A Direct Immersion Solid-Phase Microextraction...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     raw  ...                                              title\n","22890  Li, Y, Zou, S, Wang, D, Feng, G, Bao, C, Hu, J...  ...  The Effect Of Hydrofluoric Acid Treatment On T...\n","12621  N. Fucci, C. Gambelunghe, K. Aroni, R. Rossi. ...  ...  A Direct Immersion Solid-Phase Microextraction...\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"rJybdCVmbCbS"},"source":["In short, 5000 DOIs were requested, 45756 DOIs were received. Then 45756 rows of complete metadata were requested, and of them, 45280 complete rows of metadata were received. This means that after the crucial bottleneck where I was only able to request an arbitrarily (and not necessarily randomly) selected sample of 50000 DOIs, I was able to get most of the data I wanted."]},{"cell_type":"markdown","metadata":{"id":"KojOSlLjcpBI"},"source":["Let us get a sense for how clean and complete the dataset is. Do the raws really contain sufficient information to get the data we want? How can this inform the expectations and concerns we might have when developing a parser?\r\n","\r\n","The following cells may be run several times to see many different rows in the dataset."]},{"cell_type":"markdown","metadata":{"id":"K9_fqZCIebLI"},"source":["Already, it is starting to seem like most author surnames seem to be available. However, even a human processing the dataset by hand might find it difficult or impossible to determine given names. Sometimes, it is even difficult to determine whose given names or initials are whose."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"Kx6S9Y9ic_Do","executionInfo":{"status":"ok","timestamp":1614580127293,"user_tz":480,"elapsed":295,"user":{"displayName":"Peter Donovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmevrWa6lY-MoKL6lRCYdlS09IgSTYxUPNKCYZ=s64","userId":"01568505250649921698"}},"outputId":"52f3e857-5b7a-46f6-b81d-180ac4be7252"},"source":["occ.sample(5).drop(['year', 'title'], axis=1)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17477</th>\n","      <td>Birks, Y. Duty of candour and the disclosure o...</td>\n","      <td>Birks, Yvonne</td>\n","    </tr>\n","    <tr>\n","      <th>21226</th>\n","      <td>Maślińska, M, Przygodzka, M, Kwiatkowska, B, S...</td>\n","      <td>Maślińska, Maria; Przygodzka, Małgorzata; Kwia...</td>\n","    </tr>\n","    <tr>\n","      <th>21395</th>\n","      <td>Baroletti, Steven, Dell'Orfano, Heather. Medic...</td>\n","      <td>Baroletti, Steven; Dell'Orfano, Heather</td>\n","    </tr>\n","    <tr>\n","      <th>24697</th>\n","      <td>Benheim, D, Rochfort, S, Robertson, E, Potter,...</td>\n","      <td>Benheim, D.; Rochfort, S.; Robertson, E.; Pott...</td>\n","    </tr>\n","    <tr>\n","      <th>27931</th>\n","      <td>Premawardhena A, Fisher CA, Liu YT, Verma IC, ...</td>\n","      <td>Premawardhena, A; Fisher, C.A; Liu, Y.T; Verma...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     raw                                             author\n","17477  Birks, Y. Duty of candour and the disclosure o...                                      Birks, Yvonne\n","21226  Maślińska, M, Przygodzka, M, Kwiatkowska, B, S...  Maślińska, Maria; Przygodzka, Małgorzata; Kwia...\n","21395  Baroletti, Steven, Dell'Orfano, Heather. Medic...            Baroletti, Steven; Dell'Orfano, Heather\n","24697  Benheim, D, Rochfort, S, Robertson, E, Potter,...  Benheim, D.; Rochfort, S.; Robertson, E.; Pott...\n","27931  Premawardhena A, Fisher CA, Liu YT, Verma IC, ...  Premawardhena, A; Fisher, C.A; Liu, Y.T; Verma..."]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"dunnq7gle2ab"},"source":["Sometimes, titles do not end with a period or closing quotation mark; instead, they terminate with a comma, potentially making it difficult even for a human to know when the title ends and when other article data begins.\r\n","\r\n","At least a few different style guides do seem to be represented, each with different schemes for where to place the year, how to format the title, and so forth."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuiDpHG5dh1g","executionInfo":{"status":"ok","timestamp":1614580666728,"user_tz":480,"elapsed":258,"user":{"displayName":"Peter Donovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmevrWa6lY-MoKL6lRCYdlS09IgSTYxUPNKCYZ=s64","userId":"01568505250649921698"}},"outputId":"faae10b0-d05c-4d8c-8b5e-1e708c2582bd"},"source":["list(occ.sample(5).raw)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Zhao J. & Neher D. A. Soil nematode genera that predict specific types of disturbance. Appl Soil Ecol. 64, 135–141 (2013).',\n"," 'Stanogias, G, Pearce, GR. 1985b, The digestion of fibre by pigs. 2. Volatile fatty acid concentrations in large intestine digesta, Br J Nutr, 53, 531, 536, PMID: 2998446',\n"," 'Wakai, K, Naito, M, Date, C. Dietary intakes of fat and total mortality among Japanese populations with a low fat intake: the Japan Collaborative Cohort (JACC) Study. Nutr Metab (Lond) 2014; 11: 12. PMID: 24597664',\n"," 'Mao H, Yen HL, Liu Y, Lau YL, Malik Peiris JS, Tu W. Conservation of T cell epitopes between seasonal influenza viruses and the novel influenza A H7N9 virus. Virol Sin 2014; 29: 170–175. doi: 10.1007/s12250-014-3473-3 PMID: 24950786',\n"," 'Jeanjean, A, Garcia, M, Leydet, A, Montero, JL, Morere, A. Synthesis and receptor binding affinity of carboxylate analogues of the mannose 6-phosphate recognition marker, Bioorg Med Chem, 2006, 14, 3575, 82, DOI: 10.1016/j.bmc.2006.01.024, PMID: 16455258']"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"yjN3O7HrxZ80"},"source":["## TestRunner\r\n","\r\n","As before, I define a TestRunner class. For now at least, I am choosing to simply stick with percent accuracy in predicting year, author, and title as my performance metrics, because the frequency with which those attributes give successful matches with the reported metadata should be a good predictor of the frequency with which they give successful matches between different texts in a corpus.\r\n","\r\n","Logic for k-fold CVs or LOOCVs is not managed by this class. This class is strictly for computing and reporting metrics on a given dataset."]},{"cell_type":"code","metadata":{"id":"Az6xNkIrpgfj"},"source":["class TestRunner:\r\n","  \"\"\"Encapsulates logic for calculating model performance statistics.\"\"\"\r\n","  def __init__(self, model, test_set):\r\n","    \"\"\"Initializes the TestRunner with a trained MODEL that is Testable and a\r\n","    TEST_SET, which is a DataFrame that has the columns specified in the above\r\n","    section, \"Loading Datasets.\"\r\n","    \"\"\"\r\n","    self.model = model\r\n","    self.test_set = test_set\r\n","    # self.predictions will be a DataFrame of the same format as TEST_SET.\r\n","    # However, it is set to None here because it will be computed lazily.\r\n","    self.predictions = None\r\n","  def get_predictions(self):\r\n","    \"\"\"Returns a DataFrame with the same columns as the DataFrame on which the\r\n","    model was trained, as described in the \"Datasets\" section of this notebook.\r\n","    \"\"\"\r\n","    if self.predictions is None:\r\n","      self.predictions = self.model.predict(self.test_set.raw_text)\r\n","    return self.predictions\r\n","  def year_accuracy(self):\r\n","    \"\"\"Returns the proportion of publication years that the model predicts\r\n","    accurately.\r\n","    \"\"\"\r\n","    return np.mean(self.test_set.year == self.get_predictions().year)\r\n","  def surname_accuracy(self):\r\n","    \"\"\"Returns the proportion of citations from which the set of all authors'\r\n","    surnames is predicted with perfect accuracy (within the simplifications of\r\n","    de-accenting and capitalization/punctuation removal).\r\n","    \"\"\"\r\n","    return np.mean([\r\n","        (\r\n","            set(simple_preprocess(name.surname) for name in true_names)\r\n","            == set(simple_preprocess(name.surname) for name in predicted_names)\r\n","        ) for true_names, predicted_names\r\n","        in zip(self.test_set.author, self.get_predictions().author)\r\n","    ])\r\n","  def primary_author_surname_accuracy(self):\r\n","    \"\"\"Returns the proportion of citations from which the primary author's\r\n","    surname is predicted correctly. The first author who is listed in the\r\n","    dataset will be interpreted as the primary author.\r\n","    \"\"\"\r\n","    return np.mean([\r\n","        true_names[0].surname == predicted_names[0].surname\r\n","        for true_names, predicted_names\r\n","        in zip(self.test_set.author, self.get_predictions().author)\r\n","    ])\r\n","  def title_accuracy(self):\r\n","    \"\"\"Returns the proportion of citations from which the title of the cited work\r\n","    is predicted with perfect accuracy (within the simplifications of\r\n","    de-accenting and capitalization/punctuation removal).\r\n","    \"\"\"\r\n","    return np.mean(\r\n","        simple_preprocess(true_title) == simple_preprocess(predicted_title)\r\n","        for true_title, predicted_title\r\n","        in zip(self.test_set.title, self.get_predictions().title)\r\n","    )\r\n","  def quick_report(self):\r\n","    \"\"\"Prints a report of model performance without confidence intervals.\r\n","    Intended for development (debugging, preliminary results, etc.) and not for\r\n","    final reporting.\r\n","    \"\"\"\r\n","    t0 = time.time()\r\n","    get_predictions()\r\n","    elapsed_time = time.time() - t0\r\n","    print('Generated labels for {0:,} records in {:.4f} seconds ({:.4f} seconds'\r\n","          ' per record)'.format(\r\n","              len(self.test_set.index),\r\n","              elapsed_time,\r\n","              elapsed_time / len(self.test_set.index)))\r\n","    print('Surname accuracy (complete set): {:.4f}'.format(\r\n","        self.surname_accuracy()))\r\n","    print('Year accuracy: {:.4f}'.format(self.year_accuracy()))\r\n","    print('Title accuracy (with preproc): {:.4f}').format(self.title_accuracy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqx8G-vI7wii"},"source":["The following cell demonstrates the power of `simple_preprocess`, a simple, widely used utility whose function should be reasonably easy to explain to other people."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pQPhdt32_rR","executionInfo":{"status":"ok","timestamp":1614319554470,"user_tz":480,"elapsed":304,"user":{"displayName":"Peter Donovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmevrWa6lY-MoKL6lRCYdlS09IgSTYxUPNKCYZ=s64","userId":"01568505250649921698"}},"outputId":"4cfcbfbc-12aa-4ca0-d105-dc91efbe0f81"},"source":["simple_preprocess('The cát, in the hát.', deacc=True) == simple_preprocess('the cAt  iN tHe haT!!!?', deacc=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"bPviJEg5DY8P"},"source":["class CrossValidator:\r\n","  \"\"\"Reports cross validation results for a given model and dataset.\"\"\"\r\n","  # This should have a has-a relationship with TestRunner.\r\n","  # You know, it's possible sklearn has this. I will take a look."],"execution_count":null,"outputs":[]}]}